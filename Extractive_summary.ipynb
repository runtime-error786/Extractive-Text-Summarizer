{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\musta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.41.2)\n",
      "Requirement already satisfied: nltk in c:\\users\\musta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: torch in c:\\users\\musta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.4.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\musta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (3.14.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in c:\\users\\musta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.23.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\musta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\musta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\musta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\musta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\musta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\musta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\musta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\musta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: click in c:\\users\\musta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\musta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\musta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\musta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (1.12.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\musta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\musta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\musta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (2024.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\musta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\musta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\musta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\musta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\musta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\musta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in c:\\users\\musta\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~upyterlab (C:\\Users\\musta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~upyterlab (C:\\Users\\musta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~upyterlab (C:\\Users\\musta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "! pip install transformers nltk torch\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\musta\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\musta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Pre-trained Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BartForConditionalGeneration(\n",
       "  (model): BartModel(\n",
       "    (shared): Embedding(50264, 1024, padding_idx=1)\n",
       "    (encoder): BartEncoder(\n",
       "      (embed_tokens): BartScaledWordEmbedding(50264, 1024, padding_idx=1)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x BartEncoderLayer(\n",
       "          (self_attn): BartSdpaAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): GELUActivation()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): BartDecoder(\n",
       "      (embed_tokens): BartScaledWordEmbedding(50264, 1024, padding_idx=1)\n",
       "      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x BartDecoderLayer(\n",
       "          (self_attn): BartSdpaAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_fn): GELUActivation()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): BartSdpaAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=50264, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "\n",
    "MODEL_NAME = \"facebook/bart-large-cnn\"\n",
    "tokenizer = BartTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = BartForConditionalGeneration.from_pretrained(MODEL_NAME)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Preprocessing and Summarization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_article(article):\n",
    "    return sent_tokenize(article)\n",
    "\n",
    "def extract_summary(article):\n",
    "    try:\n",
    "        sentences = preprocess_article(article)\n",
    "        inputs = tokenizer(\n",
    "            \" \".join(sentences),  # Join sentences as model expects one long string\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=1024,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        inputs = {key: val.to(device) for key, val in inputs.items()}\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            summary_ids = model.generate(\n",
    "                inputs['input_ids'], \n",
    "                max_length=150,  # You can adjust the length\n",
    "                num_beams=4,     # Optional parameter to enhance quality\n",
    "                early_stopping=True\n",
    "            )\n",
    "        \n",
    "        summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "        return summary\n",
    "    except Exception as e:\n",
    "        return f\"Error during summarization: {e}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Text Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extractive Summary:\n",
      " Video shows three-month-old West African lion cubs playing in Senegal park. Lioness and cubs spotted in February by remote cameras in Niokolo-Koba National Park. Conservation group Panthera calls it a \"thrilling sign of recovery for the critically endangered\" species.\n"
     ]
    }
   ],
   "source": [
    "sample_text = \"\"\"\n",
    "At three months old, even future kings of the savannah like to play.\n",
    "\n",
    "In Senegal, a video of three cubs that would have hardly been imaginable a few years ago, has given hope that the revered West African lion, which has been decimated over time, will be revived.\n",
    "\n",
    "The US-based wild cat conservation organisation Panthera has released never-before-seen images of a lioness and three cubs spotted in February by a remote cameras in the Niokolo-Koba National Park in southeastern Senegal.\n",
    "\n",
    "In what Panthera describes as a \"thrilling sign of recovery for the critically endangered West African lion\", video footage shows the big cat eating an animal carcass while its three-month-old offspring try to imitate it.\n",
    "\n",
    "They brandish their claws and fangs, testing them out on scraps of wood or their mother's hindquarters.\n",
    "\n",
    "\"This documentation of new lion life... indicates the remarkable recovery of a population on the brink of extinction\", the organisation said in a statement.\n",
    "\n",
    "Panthera has since 2011 been working with Senegal's Department of National Parks on conservation efforts in the Niokolo-Koba park.\n",
    "\n",
    "In that time, the number of lions in the park has risen from 10 or 15 to around 30, the organisation said.\n",
    "\n",
    "The West African lion is characterised by a narrow mane and bald appearance, and is genetically distinct from the African or Asian subspecies.\n",
    "\n",
    "There are between 120 and 375 of them left, according to Panthera.\n",
    "\n",
    "Revered to the point of being cited in the Senegalese national anthem, West African lions have been decimated by poaching and the gradual loss of their habitat.\n",
    "\n",
    "Their historic range has shrunk by 99 percent, Panthera said, citing the International Union for Conservation of Nature.\n",
    "\n",
    "Florence -- the lioness caught on camera, who is thought to be nine or 10 years old -- has contributed to the population's recovery.\n",
    "\"\"\"\n",
    "\n",
    "summary = extract_summary(sample_text)\n",
    "print(\"Extractive Summary:\\n\", summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import scrolledtext, messagebox\n",
    "\n",
    "def run_gui():\n",
    "    def summarize():\n",
    "        input_text = input_text_box.get(\"1.0\", tk.END).strip()\n",
    "        if not input_text:\n",
    "            messagebox.showwarning(\"Input Error\", \"Please enter some text to summarize!\")\n",
    "            return\n",
    "        summary = extract_summary(input_text)\n",
    "        output_text_box.delete(\"1.0\", tk.END)\n",
    "        output_text_box.insert(tk.END, summary)\n",
    "\n",
    "    root = tk.Tk()\n",
    "    root.title(\"Extractive Summarization\")\n",
    "    root.geometry(\"800x600\")\n",
    "\n",
    "    tk.Label(root, text=\"Input Text:\", font=(\"Arial\", 12)).pack(anchor=\"w\", padx=10, pady=5)\n",
    "    input_text_box = scrolledtext.ScrolledText(root, wrap=tk.WORD, font=(\"Arial\", 12), height=15)\n",
    "    input_text_box.pack(fill=tk.BOTH, padx=10, pady=5, expand=True)\n",
    "\n",
    "    summarize_button = tk.Button(root, text=\"Summarize\", font=(\"Arial\", 14), bg=\"blue\", fg=\"white\", command=summarize)\n",
    "    summarize_button.pack(pady=10)\n",
    "\n",
    "    tk.Label(root, text=\"Extractive Summary:\", font=(\"Arial\", 12)).pack(anchor=\"w\", padx=10, pady=5)\n",
    "    output_text_box = scrolledtext.ScrolledText(root, wrap=tk.WORD, font=(\"Arial\", 12), height=10)\n",
    "    output_text_box.pack(fill=tk.BOTH, padx=10, pady=5, expand=True)\n",
    "\n",
    "    root.mainloop()\n",
    "\n",
    "run_gui()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extractive Summary:\n",
      " Video shows three-month-old West African lion cubs playing in Senegal park. Lioness and cubs spotted in February by remote cameras in Niokolo-Koba National Park. Conservation group Panthera calls it a \"thrilling sign of recovery for the critically endangered\" species.\n"
     ]
    }
   ],
   "source": [
    "def summarization_pipeline():\n",
    "    from IPython.display import display\n",
    "    input_text = input(\"Enter text for summarization: \").strip()\n",
    "    if input_text:\n",
    "        summary = extract_summary(input_text)\n",
    "        print(\"\\nExtractive Summary:\\n\", summary)\n",
    "    else:\n",
    "        print(\"Please enter valid text!\")\n",
    "\n",
    "summarization_pipeline()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
